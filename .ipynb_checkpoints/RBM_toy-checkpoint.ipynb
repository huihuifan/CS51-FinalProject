{
 "metadata": {
  "name": "",
  "signature": "sha256:c577f2130d45c3dad14159bc7338e16c8ab04a5e97f6365c8c8bc1f77ac7bd93"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "from __future__ import absolute_import, print_function, unicode_literals, division\n",
      "from sklearn.datasets import fetch_mldata\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import itertools\n",
      "import random as rand\n",
      "import copy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alice = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":0, \"Lego Movie\":0, \"Birdman\":0}\n",
      "eric = {\"Interstellar\":0, \"Whiplash\":0, \"Selma\":0, \"Lego Movie\":1, \"Birdman\":0}\n",
      "nancy = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":1, \"Lego Movie\":0, \"Birdman\":1}\n",
      "sarah = {\"Interstellar\":0, \"Whiplash\":1, \"Selma\":0, \"Lego Movie\":0, \"Birdman\":1}\n",
      "mike = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":1, \"Lego Movie\":1, \"Birdman\":1}\n",
      "\n",
      "data = {\"alice\":alice, \"eric\":eric, \"nancy\":nancy, \"sarah\":sarah, \"mike\":mike}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.DataFrame.from_dict(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_array = np.array(data)\n",
      "print(data_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 0 1 1 1]\n",
        " [1 0 1 1 0]\n",
        " [0 1 1 0 0]\n",
        " [0 0 1 1 0]\n",
        " [1 0 1 1 1]]\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RBM(object):\n",
      "    \"\"\"\n",
      "    Implementation of RBM\n",
      "    num_vis and num_hidden do not include bias \n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, data, num_hidden, num_visible, learning_rate):\n",
      "        # set variables based on input\n",
      "        self.data = data\n",
      "        self.data_wbias = copy.deepcopy(self.data)\n",
      "        self.num_hidden = num_hidden\n",
      "        self.num_vis = num_visible\n",
      "        self.learning_rate = learning_rate\n",
      "\n",
      "        # set weight matrix first row and first column to be RBM bias\n",
      "        self.hidden_states = np.random.rand(self.num_hidden + 1)\n",
      "        self.num_data = data.shape[0]\n",
      "        self.visible_states = np.concatenate((np.ones((self.num_data,1)), self.data),axis=1)\n",
      "        self.weights = np.random.rand(self.visible_states.shape[1], self.num_hidden + 1)\n",
      "\n",
      "    # Logistic Sigmoid Function\n",
      "    def _sigmoid(self,x):\n",
      "        return 1.0/(1.0+np.exp(-x))\n",
      "    \n",
      "    # Binomial Sampling Function\n",
      "    def _binom_sample(self, a, b):\n",
      "        prob = self._sigmoid(np.dot(a,b))\n",
      "        sample = [np.random.binomial(n=1, p=i) for i in prob]\n",
      "        return np.array(sample)\n",
      "    \n",
      "    # Predict hidden given visible\n",
      "    def _sample_h_given_v(self, v):\n",
      "        return self._binom_sample(self.weights.T, v.T)\n",
      "\n",
      "    # Predict visible given hidden\n",
      "    def _sample_v_given_h(self, h):\n",
      "        return self._binom_sample(self.weights, h)\n",
      "    \n",
      "    def propagate_up(self, vis):\n",
      "        \"\"\"\n",
      "        Propagates visible layer activation to hidden layer\n",
      "        \"\"\"\n",
      "        # add in bias\n",
      "        vis = np.insert(vis, 0, 1, axis=0)\n",
      "        vis = np.insert(vis, 0, 1, axis=1)\n",
      "        vis_activation = self._sigmoid(np.dot(vis, self.weights))\n",
      "        sample = [np.random.binomial(n=1, p=i) for i in vis_activation]\n",
      "        \n",
      "        return [vis_activation, sample]\n",
      "\n",
      "    def propagate_down(self, hid):\n",
      "        \"\"\"\n",
      "        Propagates hidden layer activation to visible layer\n",
      "        \"\"\"\n",
      "        hidden_activation = self._sigmoid(np.dot(hid, self.weights.T))\n",
      "        return hidden_activation\n",
      "\n",
      "    \n",
      "    def CDk(self, max_epochs=1000):\n",
      "        \"\"\"\n",
      "        Trains the RBM\n",
      "        \"\"\"\n",
      "        \n",
      "        for epoch in xrange(0,max_epochs):\n",
      "\n",
      "            data = np.insert(self.data, 0, 1, axis=1)\n",
      "            data = np.insert(data, 0, 1, axis=0)\n",
      "            \n",
      "            # CDk positive phase\n",
      "            up_data = self.propagate_up(self.data)\n",
      "            up_associations = np.dot(data.T, up_data[1])\n",
      "            \n",
      "            # CDk negative phase\n",
      "            down_vis_probs = self.propagate_down(up_data[0])\n",
      "            down_vis_probs[:,0] = 1 #remove the bias layer\n",
      "            down_associations = self.propagate_down(down_vis_probs.T) \n",
      "            down_associations = np.dot(down_vis_probs.T, down_associations)\n",
      "            \n",
      "            self.weights += self.learning_rate * \\\n",
      "                ((up_associations - down_associations)/self.num_data)\n",
      "                \n",
      "            error = np.sum((data - down_vis_probs) ** 2)\n",
      "            if epoch == 1000:\n",
      "                return down_vis_probs\n",
      "            #print(\"Epoch: \", epoch, \", Error: \", error)\n",
      "    \n",
      "    \n",
      "    def Gibbs_alternating(num_gen_samples):\n",
      "        samples = np.ones((num_gen_samples, self.num_vis + 1))\n",
      "        samples[0,1:] = np.random.rand(self.num_vis)\n",
      "        for i in xrange(0, self.num_data-1):\n",
      "            # calculate hidden from visible\n",
      "            v = samples [i,:]\n",
      "            h = _sample_h_given_v(v)\n",
      "            h[0] = 1\n",
      "            # calculate visible\n",
      "            v = _sample_v_given_h(h)\n",
      "            samples[i+1,:] = v      \n",
      "        return samples[:,1:]\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = RBM(data_array, 5, 3, .1)\n",
      "sample = r.CDk(max_epochs=100)\n",
      "print(r.weights)\n",
      "user = np.array([[1, 0, 0, 0, 1, 0]])\n",
      "print(r._sample_h_given_v(user))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[-7.69704459  8.74884469  9.16500559 -6.46525415 -5.24327884  8.33114786]\n",
        " [-7.84357645  3.67713255  4.51233802 -7.75254411 -6.22420225  3.83398565]\n",
        " [-7.34031869  2.49358476  2.88309592 -7.70890163 -5.59597614  2.22204052]\n",
        " [-7.71465204  8.05171557  9.37202295 -6.09222128 -5.61778737  8.32107806]\n",
        " [-7.52587823  6.19465127  7.55722078 -6.60587049 -5.48487177  6.30961843]\n",
        " [-7.98739554  3.27910423  4.31681417 -7.5477278  -5.50781582  4.03505246]]\n",
        "[0 1 1 0 0 1]\n"
       ]
      }
     ],
     "prompt_number": 14
    }
   ],
   "metadata": {}
  }
 ]
}