{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import, print_function, unicode_literals, division\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random as rand\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Obtain complete MNIST images\n",
    "DATA_PATH = '~/data'\n",
    "mnist = fetch_mldata('MNIST original', data_home=DATA_PATH)\n",
    "\n",
    "data_array = mnist.data[100:]\n",
    "\n",
    "#Convert to binary matrix \n",
    "for img in data_array:\n",
    "    img[img < 100] = 0\n",
    "    img[img > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "class RBM:\n",
    "  \n",
    "  def __init__(self, num_visible, num_hidden, learning_rate = 0.1):\n",
    "    self.num_hidden = num_hidden\n",
    "    self.num_visible = num_visible\n",
    "    self.learning_rate = learning_rate\n",
    "\n",
    "    # Initialize a weight matrix, of dimensions (num_visible x num_hidden), using\n",
    "    # a Gaussian distribution with mean 0 and standard deviation 0.1.\n",
    "    self.weights = 0.1 * np.random.randn(self.num_visible, self.num_hidden)    \n",
    "    # Insert weights for the bias units into the first row and first column.\n",
    "    self.weights = np.insert(self.weights, 0, 0, axis = 0)\n",
    "    self.weights = np.insert(self.weights, 0, 0, axis = 1)\n",
    "    print(self.weights.shape)\n",
    "\n",
    "  def train(self, data, max_epochs = 1000):\n",
    "    \"\"\"\n",
    "    Train the machine.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row is a training example consisting of the states of visible units.    \n",
    "    \"\"\"\n",
    "\n",
    "    num_examples = data.shape[0]\n",
    "\n",
    "    # Insert bias units of 1 into the first column.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    for epoch in range(max_epochs):      \n",
    "      # Clamp to the data and sample from the hidden units. \n",
    "      # (This is the \"positive CD phase\", aka the reality phase.)\n",
    "      pos_hidden_activations = np.dot(data, self.weights)      \n",
    "      pos_hidden_probs = self._logistic(pos_hidden_activations)\n",
    "      pos_hidden_states = pos_hidden_probs > np.random.rand(num_examples, self.num_hidden + 1)\n",
    "      # Note that we're using the activation *probabilities* of the hidden states, not the hidden states       \n",
    "      # themselves, when computing associations. We could also use the states; see section 3 of Hinton's \n",
    "      # \"A Practical Guide to Training Restricted Boltzmann Machines\" for more.\n",
    "      pos_associations = np.dot(data.T, pos_hidden_probs)\n",
    "\n",
    "      # Reconstruct the visible units and sample again from the hidden units.\n",
    "      # (This is the \"negative CD phase\", aka the daydreaming phase.)\n",
    "      neg_visible_activations = np.dot(pos_hidden_states, self.weights.T)\n",
    "      neg_visible_probs = self._logistic(neg_visible_activations)\n",
    "      neg_visible_probs[:,0] = 1 # Fix the bias unit.\n",
    "      neg_hidden_activations = np.dot(neg_visible_probs, self.weights)\n",
    "      neg_hidden_probs = self._logistic(neg_hidden_activations)\n",
    "      # Note, again, that we're using the activation *probabilities* when computing associations, not the states \n",
    "      # themselves.\n",
    "      neg_associations = np.dot(neg_visible_probs.T, neg_hidden_probs)\n",
    "\n",
    "      # Update weights.\n",
    "      self.weights += self.learning_rate * ((pos_associations - neg_associations) / num_examples)\n",
    "\n",
    "      error = np.sum((data - neg_visible_probs) ** 2)\n",
    "      print(\"Epoch %s: error is %s\" % (epoch, error))\n",
    "      if epoch == 10: \n",
    "            return neg_visible_probs\n",
    "\n",
    "  def run_visible(self, data):\n",
    "    \"\"\"\n",
    "    Assuming the RBM has been trained (so that weights for the network have been learned),\n",
    "    run the network on a set of visible units, to get a sample of the hidden units.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row consists of the states of the visible units.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hidden_states: A matrix where each row consists of the hidden units activated from the visible\n",
    "    units in the data matrix passed in.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_examples = data.shape[0]\n",
    "    \n",
    "    # Create a matrix, where each row is to be the hidden units (plus a bias unit)\n",
    "    # sampled from a training example.\n",
    "    hidden_states = np.ones((num_examples, self.num_hidden + 1))\n",
    "    \n",
    "    # Insert bias units of 1 into the first column of data.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    # Calculate the activations of the hidden units.\n",
    "    hidden_activations = np.dot(data, self.weights)\n",
    "    # Calculate the probabilities of turning the hidden units on.\n",
    "    hidden_probs = self._logistic(hidden_activations)\n",
    "    # Turn the hidden units on with their specified probabilities.\n",
    "    hidden_states[:,:] = hidden_probs > np.random.rand(num_examples, self.num_hidden + 1)\n",
    "    # Always fix the bias unit to 1.\n",
    "    # hidden_states[:,0] = 1\n",
    "  \n",
    "    # Ignore the bias units.\n",
    "    hidden_states = hidden_states[:,1:]\n",
    "    return hidden_states\n",
    "    \n",
    "  # TODO: Remove the code duplication between this method and `run_visible`?\n",
    "  def run_hidden(self, data):\n",
    "    \"\"\"\n",
    "    Assuming the RBM has been trained (so that weights for the network have been learned),\n",
    "    run the network on a set of hidden units, to get a sample of the visible units.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A matrix where each row consists of the states of the hidden units.\n",
    "    Returns\n",
    "    -------\n",
    "    visible_states: A matrix where each row consists of the visible units activated from the hidden\n",
    "    units in the data matrix passed in.\n",
    "    \"\"\"\n",
    "\n",
    "    num_examples = data.shape[0]\n",
    "\n",
    "    # Create a matrix, where each row is to be the visible units (plus a bias unit)\n",
    "    # sampled from a training example.\n",
    "    visible_states = np.ones((num_examples, self.num_visible + 1))\n",
    "\n",
    "    # Insert bias units of 1 into the first column of data.\n",
    "    data = np.insert(data, 0, 1, axis = 1)\n",
    "\n",
    "    # Calculate the activations of the visible units.\n",
    "    visible_activations = np.dot(data, self.weights.T)\n",
    "    # Calculate the probabilities of turning the visible units on.\n",
    "    visible_probs = self._logistic(visible_activations)\n",
    "    # Turn the visible units on with their specified probabilities.\n",
    "    visible_states[:,:] = visible_probs > np.random.rand(num_examples, self.num_visible + 1)\n",
    "    # Always fix the bias unit to 1.\n",
    "    # visible_states[:,0] = 1\n",
    "\n",
    "    # Ignore the bias units.\n",
    "    visible_states = visible_states[:,1:]\n",
    "    return visible_states\n",
    "    \n",
    "  def daydream(self, num_samples):\n",
    "    \"\"\"\n",
    "    Randomly initialize the visible units once, and start running alternating Gibbs sampling steps\n",
    "    (where each step consists of updating all the hidden units, and then updating all of the visible units),\n",
    "    taking a sample of the visible units at each step.\n",
    "    Note that we only initialize the network *once*, so these samples are correlated.\n",
    "    Returns\n",
    "    -------\n",
    "    samples: A matrix, where each row is a sample of the visible units produced while the network was\n",
    "    daydreaming.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a matrix, where each row is to be a sample of of the visible units \n",
    "    # (with an extra bias unit), initialized to all ones.\n",
    "    samples = np.ones((num_samples, self.num_visible + 1))\n",
    "\n",
    "    # Take the first sample from a uniform distribution.\n",
    "    samples[0,1:] = np.random.rand(self.num_visible)\n",
    "\n",
    "    # Start the alternating Gibbs sampling.\n",
    "    # Note that we keep the hidden units binary states, but leave the\n",
    "    # visible units as real probabilities. See section 3 of Hinton's\n",
    "    # \"A Practical Guide to Training Restricted Boltzmann Machines\"\n",
    "    # for more on why.\n",
    "    for i in range(1, num_samples):\n",
    "      visible = samples[i-1,:]\n",
    "\n",
    "      # Calculate the activations of the hidden units.\n",
    "      hidden_activations = np.dot(visible, self.weights)      \n",
    "      # Calculate the probabilities of turning the hidden units on.\n",
    "      hidden_probs = self._logistic(hidden_activations)\n",
    "      # Turn the hidden units on with their specified probabilities.\n",
    "      hidden_states = hidden_probs > np.random.rand(self.num_hidden + 1)\n",
    "      # Always fix the bias unit to 1.\n",
    "      hidden_states[0] = 1\n",
    "\n",
    "      # Recalculate the probabilities that the visible units are on.\n",
    "      visible_activations = np.dot(hidden_states, self.weights.T)\n",
    "      visible_probs = self._logistic(visible_activations)\n",
    "      visible_states = visible_probs > np.random.rand(self.num_visible + 1)\n",
    "      samples[i,:] = visible_states\n",
    "\n",
    "    # Ignore the bias units (the first column), since they're always set to 1.\n",
    "    return samples[:,1:]        \n",
    "      \n",
    "  def _logistic(self, x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 3)\n",
      "Epoch 0: error is 13739326.1055\n",
      "Epoch 1: error is 13467142.4206\n",
      "Epoch 2: error is 13311805.4429\n",
      "Epoch 3: error is 13191523.5603\n",
      "Epoch 4: error is 13065941.0622\n",
      "Epoch 5: error is 12440801.9793\n",
      "Epoch 6: error is 12591328.3384\n",
      "Epoch 7: error is 11981043.2975\n",
      "Epoch 8: error is 11827476.8985\n",
      "Epoch 9: error is 11674746.9035\n",
      "Epoch 10: error is 11285112.6143\n",
      "[[ 0.55968291  0.61130505  0.48560463]\n",
      " [-0.1606905  -0.22468598 -0.17298034]\n",
      " [-0.18526912 -0.05008884 -0.06762132]\n",
      " ..., \n",
      " [-0.17926327 -0.17508832 -0.00152439]\n",
      " [-0.16996071 -0.02599894 -0.27937329]\n",
      " [-0.16935339 -0.20429046 -0.08920321]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "axis 1 is out of bounds for an array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-24325bd16034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-84fbaef35af0>\u001b[0m in \u001b[0;36mrun_visible\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# Insert bias units of 1 into the first column of data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Calculate the activations of the hidden units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   3716\u001b[0m             raise IndexError(\n\u001b[1;32m   3717\u001b[0m                 \u001b[0;34m\"axis %i is out of bounds for an array of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3718\u001b[0;31m                 \"dimension %i\" % (axis, ndim))\n\u001b[0m\u001b[1;32m   3719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3720\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: axis 1 is out of bounds for an array of dimension 1"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  r = RBM(num_visible = 784, num_hidden = 2)\n",
    "  d = r.train(data_array, max_epochs = 11)\n",
    "  print(r.weights)\n",
    "  user = np.array(np.insert(data_array[11],0,1))\n",
    "  print(r.run_visible(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110226150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(user[1:].reshape(28, 28), cmap = 'Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.insert(data_array[11],0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
