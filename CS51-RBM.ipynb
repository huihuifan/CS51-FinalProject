{
 "metadata": {
  "name": "",
  "signature": "sha256:144233b9ce30936c8329b9430bea633bf5c70c6657fcf1b494e08d43de17b8b4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import absolute_import, print_function, unicode_literals, division\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import itertools\n",
      "import random as rand"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Toy Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alice = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":0, \"Lego Movie\":0, \"Birdman\":0}\n",
      "eric = {\"Interstellar\":0, \"Whiplash\":0, \"Selma\":0, \"Lego Movie\":1, \"Birdman\":0}\n",
      "nancy = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":1, \"Lego Movie\":0, \"Birdman\":1}\n",
      "sarah = {\"Interstellar\":0, \"Whiplash\":1, \"Selma\":0, \"Lego Movie\":0, \"Birdman\":1}\n",
      "mike = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":1, \"Lego Movie\":1, \"Birdman\":1}\n",
      "\n",
      "data = {\"alice\":alice, \"eric\":eric, \"nancy\":nancy, \"sarah\":sarah, \"mike\":mike}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 215
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.DataFrame.from_dict(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_array = np.array(data)\n",
      "print(data_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 0 1 1 1]\n",
        " [1 0 1 1 0]\n",
        " [0 1 1 0 0]\n",
        " [0 0 1 1 0]\n",
        " [1 0 1 1 1]]\n"
       ]
      }
     ],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import absolute_import, print_function, unicode_literals, division\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import itertools\n",
      "import random as rand\n",
      "import copy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 218
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RBM(object):\n",
      "    \"\"\"\n",
      "    Implementation of RBM\n",
      "    num_vis and num_hidden do not include bias \n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, data, num_hidden, num_visible, learning_rate):\n",
      "        # set variables based on input\n",
      "        self.data = data\n",
      "        self.data_wbias = copy.deepcopy(self.data)\n",
      "        self.num_hidden = num_hidden\n",
      "        self.num_vis = num_visible\n",
      "        self.learning_rate = learning_rate\n",
      "\n",
      "        # set weight matrix first row and first column to be RBM bias\n",
      "        self.hidden_states = np.random.rand(self.num_hidden + 1)\n",
      "        self.num_data = data.shape[0]\n",
      "        self.visible_states = np.concatenate((np.ones((self.num_data,1)), self.data),axis=1)\n",
      "        self.weights = np.random.rand(self.visible_states.shape[1], self.num_hidden + 1)\n",
      "\n",
      "    # Logistic Sigmoid Function\n",
      "    def _sigmoid(self,x):\n",
      "        return 1.0/(1+np.exp(-x))\n",
      "    \n",
      "    # Predict hidden given visible\n",
      "    def _sample_h_given_v(self, v):\n",
      "        prob = self._sigmoid(np.dot(self.weights.T, v.T))\n",
      "        sample = [np.random.binomial(n=1, p=i) for i in prob]\n",
      "        return np.array(sample)\n",
      "\n",
      "    # Predict visible given hidden\n",
      "    def _sample_v_given_h(self, h):\n",
      "        prob =  self._sigmoid(np.dot(self.weights, h))\n",
      "        sample = [np.random.binomial(n=1, p=i) for i in prob]\n",
      "        return np.array(sample)\n",
      "    \n",
      "    def propagate_up(self, vis):\n",
      "        \"\"\"\n",
      "        Propagates visible layer activation to hidden layer\n",
      "        \"\"\"\n",
      "        # add in bias\n",
      "        vis = np.insert(vis, 0, 1, axis=0)\n",
      "        vis = np.insert(vis, 0, 1, axis=1)\n",
      "        vis_activation = self._sigmoid(np.dot(vis, self.weights))\n",
      "        sample = [np.random.binomial(n=1, p=i) for i in vis_activation]\n",
      "        return [vis_activation, sample]\n",
      "\n",
      "    def propagate_down(self, hid):\n",
      "        \"\"\"\n",
      "        Propagates hidden layer activation to visible layer\n",
      "        \"\"\"\n",
      "        hidden_activation = self._sigmoid(np.dot(hid, self.weights.T))\n",
      "        return hidden_activation\n",
      "\n",
      "    \n",
      "    def CDk(self, max_epochs=1000):\n",
      "        \"\"\"\n",
      "        Trains the RBM\n",
      "        \"\"\"\n",
      "        \n",
      "        for epochs in xrange(0,max_epochs):\n",
      "            \n",
      "            data = np.insert(self.data, 0, 1, axis=1)\n",
      "            data = np.insert(self.data, 0, 1, axis=0)\n",
      "            \n",
      "            # CDk positive phase\n",
      "            up_data = self.propagate_up(self.data)\n",
      "            up_associations = np.dot(data.T, up_data[1])\n",
      "            \n",
      "            # CDk negative phase\n",
      "            down_vis_probs = self.propagate_down(up_data[0])\n",
      "            down_vis_probs[:,0] = 1 #remove the bias layer\n",
      "            down_associations = self.propagate_down(down_vis_probs.T)\n",
      "            down_associations = np.dot(down_vis_probs.T, down_associations)\n",
      "            \n",
      "            self.weights += self.learning_rate * \\\n",
      "                ((up_associations - down_associations)/self.num_data)\n",
      "                \n",
      "            error = np.sum((self.data - down_vis_probs) ** 2)\n",
      "            print(\"Epoch: \" + epoch + \", Error: \" + error)\n",
      "        \n",
      "    \n",
      "    def Gibbs_alternating(num_gen_samples):\n",
      "        samples = np.ones((num_gen_samples, self.num_vis + 1))\n",
      "        samples[0,1:] = np.random.rand(self.num_vis)\n",
      "        for i in xrange(0, self.num_data-1):\n",
      "            # calculate hidden from visible\n",
      "            v = samples [i,:]\n",
      "            h = _sample_h_given_v(v)\n",
      "            h[0] = 1\n",
      "            # calculate visible\n",
      "            v = _sample_v_given_h(h)\n",
      "            samples[i+1,:] = v      \n",
      "        return samples[:,1:]\n",
      "            \n",
      "            \n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r = RBM(data_array, 5, 3, .1)\n",
      "r.CDk(max_epochs=10)\n",
      "print(r.weights)\n",
      "user = np.array([[1, 0, 0, 0, 1, 0]])\n",
      "print(r._sample_h_given_v(user))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "operands could not be broadcast together with shapes (5,6) (6,6) ",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-235-a191f6156aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRBM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_h_given_v\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-233-b491b05f0d0c>\u001b[0m in \u001b[0;36mCDk\u001b[0;34m(self, max_epochs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mdown_associations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown_vis_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown_associations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup_associations\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdown_associations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdown_vis_probs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,6) (6,6) "
       ]
      }
     ],
     "prompt_number": 235
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}