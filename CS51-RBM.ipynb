{
 "metadata": {
  "name": "",
  "signature": "sha256:2a7de5b8dd8a5bf59bde35161a437ab1f135ccc26ea4979973b49d6c86bbf5d4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import absolute_import, print_function, unicode_literals, division\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "import random as rand"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Toy Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alice = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":0, \"Lego Movie\":0, \"Birdman\":0}\n",
      "eric = {\"Interstellar\":0, \"Whiplash\":0, \"Selma\":0, \"Lego Movie\":1, \"Birdman\":0}\n",
      "nancy = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":1, \"Lego Movie\":0, \"Birdman\":1}\n",
      "sarah = {\"Interstellar\":0, \"Whiplash\":1, \"Selma\":0, \"Lego Movie\":0, \"Birdman\":1}\n",
      "mike = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":1, \"Lego Movie\":1, \"Birdman\":1}\n",
      "\n",
      "data = {\"alice\":alice, \"eric\":eric, \"nancy\":nancy, \"sarah\":sarah, \"mike\":mike}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.DataFrame.from_dict(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_array = np.array(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RBM(object):\n",
      "\n",
      "\tdef __init__(self, num_visible, num_hidden, activation_func, learning_rate):\n",
      "\t\tself.num_visible = num_visible\n",
      "\t\tself.num_hidden = num_hidden\n",
      "        \n",
      "        self.hbias = None\n",
      "        self.vbias = None\n",
      "        \n",
      "\t\tself.visible = 0\n",
      "        self.hidden = 0\n",
      "\t\tself.learning_rate = learning_rate\n",
      "\t\tself.activation_func = activation_func \n",
      "\t\t# Initialize internal variables \n",
      "\t\tself.weights = np.random.rand((self.num_visible+1,self.num_hidden+1)) + 0.01  # includes bias index 0\n",
      "\n",
      "\n",
      "\t'''\n",
      "\tPrivate Methods\n",
      "\t'''\n",
      "\n",
      "\t# Hopfield Energy Function\n",
      "\tdef _energy(self, visible_states, hidden_states):  \n",
      "\t\treturn (- np.dot(visible_states, self.weights[:,0]) - \\\\\n",
      "\t\t\t\tnp.dot(hidden_states, self.weights[0,:]) - \\\\\n",
      "\t\t\t\tnp.dot(hidden_states[1:], \\\\\n",
      "\t\t\t\tnp.dot(W[1:,1:],visible_states[1:])))\n",
      "\n",
      "\t# Logistic Sigmoid Function\n",
      "\tdef _sigmoid(self, x):\n",
      "\t\treturn 1/(1+np.exp(-x))\n",
      "    \n",
      "    \t# Partition Function\n",
      "\tdef _Z(self):\n",
      "        Z = 0\n",
      "\t\tfor s1 in xrange(self.visible.shape[0]):\n",
      "            for s2 in xrange(self.hidden.shape[0]):\n",
      "                Z += np.exp(-1 * self.energy(self.visible[s1], self.hidden[s2])\n",
      "        return Z\n",
      "\n",
      "\t# Probability of Visible/Hidden Pair \n",
      "\tdef _probability(self, visible_states, hidden_states):  \n",
      "\t\treturn (1 / self.Z()) * np.exp(-1 * self.energy(visible_states, hidden_states)\n",
      "\n",
      "\t# Probability of Visible\n",
      "\tdef _probability_visible(self, visible_states): \n",
      "        p = 0\n",
      "        for s1 in xrange(self.hidden.shape[0]):\n",
      "            p += np.exp(-1 * self.energy(visible_states, hidden[s1]))\n",
      "\t\treturn (1 / self.Z()) * p\n",
      "\n",
      "\t# Get unbiased sample of <data>\n",
      "\t#... TODO\n",
      "\n",
      "\t# Get unbiased sample of <model>\n",
      "\t#... TODO\n",
      "\n",
      "    # Derivative of the log probability of a training vector with respect to a weight\n",
      "\tdef _deriv_log_prob(self, visible_states, i, j):\n",
      "\t\treturn TODO\n",
      "\n",
      "\t# Stochastic steepest ascent in the log probability of the training data\n",
      "\tdef _delta(self, i, j, visible_states):\n",
      "\t\treturn TODO\n",
      "\n",
      "\t# Gibbs Sampler\n",
      "\t... TODO\n",
      "\n",
      "\n",
      "\t'''\n",
      "\tPublic Methods\n",
      "\t'''\n",
      "\n",
      "\t# Train learner\n",
      "\tdef train(self, data):\n",
      "\t\t# update the visible and hidden states to the actual data\n",
      "        self.visible = np.hstack (np.ones((data.shape[0], 1)), data)\n",
      "        self.hidden = np.random.rand (self.num_visible, self.num_hidden + 1)\n",
      "        \n",
      "        \n",
      "\t# Predict Hidden to Visible\n",
      "\tdef predict_H2V(self, hidden_states):\n",
      "\t\treturn TODO\n",
      "\n",
      "\t# Predict Visible to Hidden\n",
      "\tdef predict_V2H(self, visible_states):\n",
      "\t\treturn TODO\n",
      "        \n",
      "    def CDk(self, k):\n",
      "        \"\"\"\n",
      "        Implementation of k-step contrastive divergence by running a k step Gibbs chain\n",
      "\n",
      "        Uses: \n",
      "        RBM with m visible states and n hidden states\n",
      "        Batch of training data\n",
      "\n",
      "        Outputs\n",
      "        Gradient approximation \n",
      "        \"\"\"\n",
      "        # d represents the change in w, b, and c respectively\n",
      "        d_w = np.zeros((self.num_vis_states, self.num_hidden_states))\n",
      "        d_b = np.zeros(self.num_hidden_states)\n",
      "        d_c = np.zeros(self.num_vis_states)\n",
      "\n",
      "        for vis_state in self.batch:\n",
      "            v0 = vis_state\n",
      "\n",
      "            for t in xrange(0, self.k-1):\n",
      "                for i in xrange(1, n):\n",
      "                    # sample from h_i(t) \n",
      "\n",
      "                for j in xrange(1, m):\n",
      "                    # sample from v_j(t+1)\n",
      "\n",
      "        #for i in xrange(1, n):\n",
      "            #for j in xrange(1, m):\n",
      "                #wij = wij +\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    # possible extension: better gibbs chain with tempering"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "unexpected character after line continuation character (<ipython-input-12-faede64159c2>, line 22)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-faede64159c2>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    return (- np.dot(visible_states, self.weights[:,0]) - \\\t\t\t\tnp.dot(hidden_states, self.weights[0,:]) - \\\t\t\t\tnp.dot(hidden_states[1:], \\\t\t\t\tnp.dot(W[1:,1:],visible_states[1:])))\u001b[0m\n\u001b[0m                                                           \t\t\t\t                                            \t\t\t\t                           \t\t\t\t                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
       ]
      }
     ],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}