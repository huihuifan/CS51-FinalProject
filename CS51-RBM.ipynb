{
 "metadata": {
  "name": "",
  "signature": "sha256:b79ae53247341a1fb6b612c777d498e1c10e2a3130a1c3f1a5284a7436c5491c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import absolute_import, print_function, unicode_literals, division\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import itertools\n",
      "import random as rand"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Toy Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alice = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":0, \"Lego Movie\":0, \"Birdman\":0}\n",
      "eric = {\"Interstellar\":0, \"Whiplash\":0, \"Selma\":0, \"Lego Movie\":1, \"Birdman\":0}\n",
      "nancy = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":1, \"Lego Movie\":0, \"Birdman\":1}\n",
      "sarah = {\"Interstellar\":0, \"Whiplash\":1, \"Selma\":0, \"Lego Movie\":0, \"Birdman\":1}\n",
      "mike = {\"Interstellar\":1, \"Whiplash\":1, \"Selma\":1, \"Lego Movie\":1, \"Birdman\":1}\n",
      "\n",
      "data = {\"alice\":alice, \"eric\":eric, \"nancy\":nancy, \"sarah\":sarah, \"mike\":mike}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.DataFrame.from_dict(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_array = np.array(data)\n",
      "print(data_array)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0 0 1 1 1]\n",
        " [1 0 1 1 0]\n",
        " [0 1 1 0 0]\n",
        " [0 0 1 1 0]\n",
        " [1 0 1 1 1]]\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class RBM(object):\n",
      "\n",
      "    def __init__(self, num_visible, num_hidden, learning_rate):\n",
      "        self.num_visible = num_visible\n",
      "        self.num_hidden = num_hidden\n",
      "        self.hbias = None\n",
      "        self.vbias = None\n",
      "        \n",
      "        self.visible = 0\n",
      "        self.hidden = 0\n",
      "        self.learning_rate = learning_rate\n",
      "        # Initialize internal variables \n",
      "        self.weights = np.random.rand(1+self.num_visible,1+self.num_hidden) + 0.01  # includes bias index 0\n",
      "\n",
      "\n",
      "    '''\n",
      "    Private Methods\n",
      "    '''\n",
      "\n",
      "    # Hopfield Energy Function\n",
      "    def _energy(self, visible_states, hidden_states):  \n",
      "        # Debugging matrix dimensions\n",
      "        # print(visible_states.shape, hidden_states.shape, self.weights.shape)\n",
      "        ax = np.dot(visible_states, self.weights[0:,0])\n",
      "        bx = np.dot(hidden_states, self.weights[0,1:])\n",
      "        cx = np.dot(self.weights[0:,1:].T,visible_states[0:,None])\n",
      "        dx = np.dot((hidden_states[0:, None]), cx.T)\n",
      "        \n",
      "        energy_fun = - ax - bx - dx\n",
      "        #print(energy_fun)\n",
      "        return (energy_fun)\n",
      "\n",
      "    # Logistic Sigmoid Function\n",
      "    def _sigmoid(self, x):\n",
      "        return 1/(1+np.exp(-x))\n",
      "    \n",
      "    # Partition Function\n",
      "    def _Z(self):\n",
      "        Zval = 0\n",
      "        for s1 in xrange(self.visible.shape[0]):\n",
      "            for s2 in xrange(self.hidden.shape[0]):\n",
      "                Zval += np.exp(-1 * self.energy(self.visible[s1], self.hidden[s2]))\n",
      "        return Zval\n",
      "\n",
      "    # Probability of Visible/Hidden Pair \n",
      "    def _probability(self, visible_states, hidden_states):  \n",
      "        return (1 / self.Z()) * np.exp(-1 * self.energy(visible_states, hidden_states))\n",
      "\n",
      "    # Probability of Visible\n",
      "    def _probability_visible(self, visible_states): \n",
      "        possible_hidden = map(list, itertools.product([0, 1], repeat=self.num_hidden))\n",
      "        p = 0\n",
      "        for s1 in xrange(len(self.possible_hidden)):\n",
      "            p += np.exp(-1 * self.energy(visible_states, possible_hidden[s1]))\n",
      "        return (1 / self.Z()) * p\n",
      "\n",
      "    def _samp_h_given_v(self, v0_samp):\n",
      "        sig_calc = _sigmoid(v0_samp)\n",
      "        h1_samp = np.random.binomial(size=len(v0_samp), n=1, p=sig_calc)\n",
      "        return h1_samp\n",
      "        \n",
      "    def _samp_v_given_h(self, h0_samp):\n",
      "        sig_calc = _sigmoid(h0_samp)\n",
      "        v1_samp = np.random.binomial(size=len(h0_samp), n=1, p=sig_calc)\n",
      "        return v1_samp\n",
      "        \n",
      "    def _propagate_up(self):\n",
      "        vis_activation = _sigmoid(np.dot(self.visible, self.weights.T) + self.hbias)\n",
      "        return vis_activation\n",
      "    \n",
      "    def _propagate_down(self):\n",
      "        hidden_activation = _sigmoid(np.dot(self.hidden, self.weights) + self.vbias)\n",
      "        return hidden_activation\n",
      "\n",
      "    # Derivative of the log probability of a training vector with respect to a weight\n",
      "    def _deriv_log_prob(self, visible_states, i, j):\n",
      "        return TODO\n",
      "\n",
      "    # Stochastic steepest ascent in the log probability of the training data\n",
      "    def _delta(self, i, j, visible_states):\n",
      "        return TODO\n",
      "\n",
      "\n",
      "    '''\n",
      "    Public Methods\n",
      "    '''\n",
      "\n",
      "    # Train learner\n",
      "    def train(self, data):\n",
      "        # update the visible and hidden states to the actual data\n",
      "        self.visible = np.hstack((np.ones((data.shape[0], 1)), data))\n",
      "        self.hidden = np.random.rand(self.num_hidden)\n",
      "        \n",
      "        #if self.hbias is None:\n",
      "            #self.hbias = \n",
      "            \n",
      "        #if self.vbias is None:\n",
      "        \n",
      "        \n",
      "    # Predict Hidden to Visible\n",
      "    def predict_H2V(self, hidden_states):\n",
      "        return TODO\n",
      "\n",
      "    # Predict Visible to Hidden\n",
      "    def predict_V2H(self, visible_states):\n",
      "        return TODO\n",
      "        \n",
      "        \n",
      "    def CDk(self, k):\n",
      "        \"\"\"\n",
      "        Implementation of k-step contrastive divergence by running a k step Gibbs chain\n",
      "\n",
      "        Uses: \n",
      "        RBM with m visible states and n hidden states\n",
      "        Batch of training data\n",
      "\n",
      "        Outputs\n",
      "        Gradient approximation \n",
      "        \"\"\"\n",
      "        # d represents the change in w, b, and c respectively\n",
      "        d_w = np.zeros((self.num_vis_states, self.num_hidden_states))\n",
      "        d_b = np.zeros(self.num_hidden_states)\n",
      "        d_c = np.zeros(self.num_vis_states)\n",
      "\n",
      "        for vis_state in self.batch:\n",
      "            v0 = vis_state\n",
      "            \n",
      "        return None\n",
      "\n",
      "            #for t in xrange(0, self.k-1):\n",
      "                #for i in xrange(1, n):\n",
      "                    # sample from h_i(t) \n",
      "\n",
      "                #for j in xrange(1, m):\n",
      "                    # sample from v_j(t+1)\n",
      "\n",
      "        #for i in xrange(1, n):\n",
      "            #for j in xrange(1, m):\n",
      "                #wij = wij +\n",
      "\n",
      "\n",
      "    def debug(self):\n",
      "        print(self.visible, self.hidden)\n",
      "        print(self._energy(self.visible[2,:], self.hidden))\n",
      "        print(self.visible[2,:], self.hidden)\n",
      "\n",
      "\n",
      "    # possible extension: better gibbs chain with tempering"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "RBM_agent = RBM(5, 3, 0.1)\n",
      "RBM_agent.train(data_array)\n",
      "RBM_agent.debug()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  0.  0.  1.  1.  1.]\n",
        " [ 1.  1.  0.  1.  1.  0.]\n",
        " [ 1.  0.  1.  1.  0.  0.]\n",
        " [ 1.  0.  0.  1.  1.  0.]\n",
        " [ 1.  1.  0.  1.  1.  1.]] [ 0.29166313  0.72928765  0.84371536]\n",
        "[[-2.73115806 -2.91491804 -2.8609778 ]\n",
        " [-3.35828299 -3.81776474 -3.68289014]\n",
        " [-3.52226025 -4.05383625 -3.89779936]]\n",
        "[ 1.  0.  1.  1.  0.  0.] [ 0.29166313  0.72928765  0.84371536]\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lst = map(list, itertools.product([0, 1], repeat=3))\n",
      "print(lst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]]\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}