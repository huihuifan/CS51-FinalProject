{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import, print_function, unicode_literals, division\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random as rand\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_dbg(x):\n",
    "    print(x.shape, \": \\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    \"\"\"\n",
    "    NOTE: Matrix operations are modified from RBM file\n",
    "    In particular, we have an an an input of n data points with\n",
    "    dimension d as a d-by-n matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, data, num_hidden, learn_rate):\n",
    "        # First row are the target values\n",
    "        self.targets = data[0]\n",
    "        self.data = data[1:,:]\n",
    "        self.num_data = data.shape[1]\n",
    "        self.num_visible = data.shape[0] - 1\n",
    "        self.num_hidden = num_hidden\n",
    "        self.learn_rate = learn_rate\n",
    "        \n",
    "        self.min_data = np.amin(self.targets)\n",
    "        self.max_data = np.amax(self.targets)\n",
    "        self.state_size = 2 * (self.max_data - self.min_data) + 4\n",
    "        \n",
    "        self.weights = np.random.rand(self.num_visible + 1, self.num_hidden)\n",
    "        \n",
    "        self.out_scale = self.state_size * np.ones((self.num_hidden,1))\n",
    "        self.out_weights = np.random.rand(self.num_hidden,1)\n",
    "        \n",
    "        self.data = np.insert(self.data, 0, 1, axis = 0)\n",
    "    \n",
    "    def _sigmoid(self,x):\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "        \n",
    "    def _activated(self,mat):\n",
    "        activated = self._sigmoid(np.dot(self.weights.T,mat))\n",
    "        return activated\n",
    "    \n",
    "    def _out_linsum(self,mat):\n",
    "        linsum = np.dot(self.out_weights.T,mat)\n",
    "        return linsum\n",
    "    \n",
    "    def _gradient(self,mat):\n",
    "        w = copy.deepcopy(mat)\n",
    "        for elt in np.nditer(w,op_flags=['readwrite']):\n",
    "            elt[...] = elt - elt * elt\n",
    "        return w\n",
    "    \n",
    "    def _scale(self,mat):\n",
    "        scaled = np.dot(self.out_scale,mat)\n",
    "        return scaled\n",
    "    \n",
    "    def _feed_forward(self):\n",
    "        data_copy = copy.deepcopy(self.data)\n",
    "        for i in range(0,self.num_data):\n",
    "            data_col = data_copy[:,i]\n",
    "            data_col = np.reshape(data_col, (-1, 1))\n",
    "            \n",
    "            activated_output = (self._activated(data_col))\n",
    "            guess = self._scale(2 * activated_output - 1)\n",
    "            guess = self._out_linsum(guess)\n",
    "            #print(\"Guess: \", guess)\n",
    "            \n",
    "            error = self.targets[i] - guess\n",
    "            grad = (self._gradient(activated_output))\n",
    "            \n",
    "            c = (error * self.learn_rate)[0]\n",
    "            wt_change = c * grad * data_col\n",
    "            \n",
    "            self.weights = wt_change + self.weights\n",
    "            self.weights = self.weights\n",
    "        \n",
    "        #print(\"New weights: \",self.weights)\n",
    "        \n",
    "    def _prop_backward(self):\n",
    "        return None\n",
    "    \n",
    "    def _calc_error(self, mat):\n",
    "        return None\n",
    "    \n",
    "    def pred(self, test):\n",
    "        test_copy = copy.deepcopy(test)\n",
    "        test_copy = np.insert(test_copy, 0, 1, axis = 0)\n",
    "        pred_p = self._activated(test_copy)\n",
    "        pred = 2 * pred_p - 1\n",
    "        print(\"Pred1:\", pred, \" \\n and size: \", np.shape(pred))\n",
    "        #pred = np.dot(self.out_scale.T,pred)\n",
    "        pred = 1 * np.dot(self.out_weights.T,pred)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights^T: \n",
      " [[ 0.89433334  0.87292369  0.45852058]\n",
      " [ 0.29373452  0.55405624  0.36302391]]\n",
      "Targets: \n",
      "[-1. -1. -1.  1. -1. -1. -1. -1.  3.  1. -1. -3.  1.  3. -3. -1. -1. -3.\n",
      " -3. -3. -3. -1.  1.  1.  1. -1. -1.  3. -3. -3.  1.  1.  3. -3. -3.  3.\n",
      " -3.  1. -1.  3.  1.  1.  3.  3. -3.  3.  1.  3.  3. -3. -1. -1. -1. -3.\n",
      " -1.  1. -1.  3. -3. -1. -3. -1. -3. -3.  3. -3. -1. -1. -1. -3.  3. -1.\n",
      " -3. -3. -1. -3.  3.  1.  3. -3. -1.  3. -1.  1. -3.  3.  3.  1.  3. -3.\n",
      " -3.  1.  3.  1. -1. -3.  3.  1.  3.  1.  3.  3.  3. -3.  1. -1. -3.  1.\n",
      " -1.  3.  1.  1. -3. -3.  1. -3.  1. -3. -1. -3.  1. -1. -1.  3. -3.  3.\n",
      "  1.  3. -3. -1.  1.  3. -3. -1. -1. -3. -1.  3.  3.  1. -3.  3. -1.  1.\n",
      " -3. -1.  3.  1.  3.  1.  3. -3.  3.  3.  1. -3. -1.  1. -3.  3.  1.  1.\n",
      " -1.  1. -1.  1.  3.  3. -3.  1.  3.  1.  1.  1.  3. -3.  1. -1. -1. -1.\n",
      "  3.  3.  3.  1. -3. -1. -1.  3. -1. -3.  1.  1. -1. -3.  3. -3. -3.  1.\n",
      " -1. -3.  3. -3.  3.  3. -1.  3.  3. -3. -1. -3.  3. -3.  1.  3.  3. -1.\n",
      " -1.  1. -3. -3.  1.  1.  1.  3. -1. -3. -1. -1. -3. -1. -3. -3. -1. -3.\n",
      " -1.  1. -3.  3. -3.  3.  1. -3.  3.  3. -1. -3.  1.  3. -1.  3. -3. -3.\n",
      "  3.  1.  1.  1. -1.  3. -1. -3.  3. -3. -3. -1.  1. -1.  3. -1. -1.  1.\n",
      "  3.  1.  3. -1.  1. -1. -1. -1. -3. -1.  1. -1. -1.  3.  1.  3. -3.  3.\n",
      " -1.  1.  3. -1. -1.  1.  3.  3.  3.  1. -3. -1. -3.  3. -1. -1. -1. -1.\n",
      " -1.  3.  3. -3.  1. -3.  1.  1.  3. -3.  1. -1.  3.  3. -3.  3.  3. -1.\n",
      " -1.  3.  1.  1. -1. -3. -3.  1. -1.  3.  1. -3. -1.  1. -3. -3. -1.  3.\n",
      " -1.  1.  1.  1.  3. -3. -3.  3.  1. -1. -1.  1. -3.  1. -3. -1. -1. -1.\n",
      " -1. -3.  1. -3.  1. -1.  1. -1.  1.  3.  3. -1.  1. -3.  3. -3. -1.  3.\n",
      "  1.  1.  1. -1.  1.  3. -1. -1.  1.  3.  1.  3. -3.  3. -3. -1.  1. -3.\n",
      " -3. -1. -1.  3. -1. -1. -1. -3.  3.  1. -3.  1.  3. -1. -1. -3. -1. -3.\n",
      "  1. -1.  3. -3.  1.  3.  1. -3.  3.  1. -1.  1.  3. -1.  1.  3. -1.  1.\n",
      "  3. -1. -3.  3.  3. -1.  3. -3.  3.  3. -3. -3.  1.  1.  1.  1. -3. -1.]\n"
     ]
    }
   ],
   "source": [
    "# See www.cse.unsw.edu.au/~cs9417ml/MLP2/\n",
    "# https://www.hiit.fi/u/ahonkela/dippa/node41.html\n",
    "dims = 3\n",
    "data_pts = 50 * dims ** 2\n",
    "sample_data = np.sign(2*np.random.rand(dims,data_pts)-1)\n",
    "sample_data[0] = (2 * sample_data[1] + 1 * sample_data[2]) \n",
    "# Need to write binary target values for data as well for MLP\n",
    "#mat_dbg(sample_data)\n",
    "MLP_1 = MLP(sample_data,2,0.01)\n",
    "print(\"Weights^T: \\n\",MLP_1.weights.T)\n",
    "print(\"Targets: \")\n",
    "print(MLP_1.targets)\n",
    "#print(\"Data sample: \\n\",MLP_1.data[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-b2c075428316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mMLP_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#MLP_1._feed_forward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-225-4e968c144219>\u001b[0m in \u001b[0;36m_feed_forward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mactivated_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mactivated_output\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_out_linsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m#print(\"Guess: \", guess)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-225-4e968c144219>\u001b[0m in \u001b[0;36m_scale\u001b[0;34m(self, mat)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "iterations = 2\n",
    "for i in range(0,iterations):\n",
    "    MLP_1._feed_forward()\n",
    "#MLP_1._feed_forward()\n",
    "print(\"Weights: \\n\", MLP_1.weights)\n",
    "results = np.dot(MLP_1.weights.T,MLP_1.data)\n",
    "print(\"Targets: \\n\", MLP_1.targets)\n",
    "print(\"Results: \\n\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1. -1. -1. -1. -1. -1.  1. -1.  1.]\n",
      " [-1.  1.  1. -1. -1. -1. -1. -1.  1. -1.]]\n",
      "targets:  [ 1. -1. -1. -3. -3. -3. -3.  1. -1.  1.]\n",
      "Pred1: [[ 0.2745526  -0.24282029 -0.24282029 -0.70129314 -0.70129314 -0.70129314\n",
      "  -0.70129314  0.2745526  -0.24282029  0.2745526 ]\n",
      " [ 0.36680258 -0.134828   -0.134828   -0.71972672 -0.71972672 -0.71972672\n",
      "  -0.71972672  0.36680258 -0.134828    0.36680258]]  \n",
      " and size:  (2, 10)\n",
      "Shape: (1, 10)\n",
      "Guesses: \n",
      " [[ 0.08071335 -0.04311095 -0.04311095 -0.17377399 -0.17377399 -0.17377399\n",
      "  -0.17377399  0.08071335 -0.04311095  0.08071335]]\n"
     ]
    }
   ],
   "source": [
    "dims = 2\n",
    "test_pts = 10\n",
    "test_data = np.sign(2*np.random.rand(dims,test_pts)-1)\n",
    "print(test_data)\n",
    "print(\"targets: \", 2 * test_data[0] + 1 * test_data[1])\n",
    "a = MLP_1.pred(test_data)\n",
    "print(\"Shape:\",np.shape(a))\n",
    "print(\"Guesses: \\n\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59697608]\n",
      " [ 0.84993872]]\n"
     ]
    }
   ],
   "source": [
    "print(MLP_1.out_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
