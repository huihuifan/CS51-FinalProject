{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import absolute_import, print_function, unicode_literals, division\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random as rand\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_dbg(x):\n",
    "    print(x.shape, \": \\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    \"\"\"\n",
    "    NOTE: Matrix operations are modified from RBM file\n",
    "    In particular, we have an an an input of n data points with\n",
    "    dimension d as a d-by-n matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, data, num_hidden, learn_rate):\n",
    "        # First row are the target values\n",
    "        self.targets = data[0]\n",
    "        self.data = data[1:,:]\n",
    "        self.num_data = data.shape[1]\n",
    "        self.num_visible = data.shape[0] - 1\n",
    "        self.num_hidden = num_hidden\n",
    "        self.learn_rate = learn_rate\n",
    "        \n",
    "        self.weights = np.random.rand(self.num_visible, self.num_hidden)\n",
    "        self.weights = np.insert(self.weights, 0, 1, axis = 0)\n",
    "        self.data = np.insert(self.data, 0, 1, axis = 0)\n",
    "    \n",
    "    def _sigmoid(self,x):\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "        \n",
    "    def _activated(self,mat):\n",
    "        activated = self._sigmoid(np.dot(self.weights.T,mat))\n",
    "        #activated = np.sign(activated - 0.5) # -0.5 for logistic sigmoid, 0 for tanh\n",
    "        #for elt in np.nditer(activated,op_flags=['readwrite']):\n",
    "        #    if elt == 0: \n",
    "        #        elt[...] = 1\n",
    "        return activated\n",
    "    \n",
    "    def _gradient(self,mat):\n",
    "        w = copy.deepcopy(mat)\n",
    "        for elt in np.nditer(w,op_flags=['readwrite']):\n",
    "            elt[...] = elt - elt * elt\n",
    "        return w\n",
    "    \n",
    "    def _feed_forward(self):\n",
    "        data_copy = copy.deepcopy(self.data)\n",
    "        print(self.num_data)\n",
    "        print(\"Initial weights: \",self.weights)\n",
    "        for i in range(0,self.num_data):\n",
    "            data_col = data_copy[:,i]\n",
    "            data_col = np.reshape(data_col, (-1, 1))\n",
    "            prod1 = np.dot(self.weights.T,data_col)\n",
    "            guess = self._activated(data_col)\n",
    "            error = self.targets[i] - guess\n",
    "            print(\"Guess: \", guess, \" and target: \", self.targets[i])\n",
    "            grad = self._gradient(guess)\n",
    "            s = (error * self.learn_rate)[0][0] \n",
    "            print(\"Grad: \",grad, \"\\n Error:\", error)\n",
    "            wt_change = s * grad\n",
    "            print(\"Weight change: \", wt_change)\n",
    "            print(\"Pre new weightz: \", wt_change + self.weights)\n",
    "            self.weights = wt_change + self.weights\n",
    "            self.weights = self.weights/(np.sum(self.weights))\n",
    "            print(\"New weights: \",self.weights)\n",
    "            \n",
    "        \n",
    "    def _prop_backward(self):\n",
    "        return None\n",
    "    \n",
    "    def _calc_error(self,mat):\n",
    "        return None\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 10) : \n",
      " [[-1.  1. -1.  1.  1. -1.  1.  1. -1.  1.]\n",
      " [-1.  1. -1.  1.  1. -1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1.  1. -1. -1.  1. -1. -1. -1.]\n",
      " [-1. -1.  1. -1.  1.  1. -1.  1. -1.  1.]\n",
      " [-1. -1.  1. -1.  1.  1. -1.  1. -1.  1.]\n",
      " [ 1.  1.  1.  1. -1.  1.  1. -1. -1.  1.]]\n",
      "Weights^T: \n",
      " [[ 1.          0.98576224  0.9594031   0.83024386  0.37949296  0.9569474 ]]\n",
      "Targets: \n",
      "[-1.  1. -1.  1.  1. -1.  1.  1. -1.  1.]\n",
      "Data: \n",
      " [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [-1.  1. -1.  1.  1. -1.  1.  1. -1.  1.]\n",
      " [ 1. -1. -1.  1. -1. -1.  1. -1. -1. -1.]\n",
      " [-1. -1.  1. -1.  1.  1. -1.  1. -1.  1.]\n",
      " [-1. -1.  1. -1.  1.  1. -1.  1. -1.  1.]\n",
      " [ 1.  1.  1.  1. -1.  1.  1. -1. -1.  1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   0,  -2,  -6, -12])"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See www.cse.unsw.edu.au/~cs9417ml/MLP2/\n",
    "sample_data = np.sign(1-2*np.random.rand(6,10))\n",
    "sample_data[0] = sample_data[1]\n",
    "# Need to write binary target values for data as well for MLP\n",
    "mat_dbg(sample_data)\n",
    "MLP_1 = MLP(sample_data,1,0.05)\n",
    "print(\"Weights^T: \\n\",MLP_1.weights.T)\n",
    "print(\"Targets: \")\n",
    "print(MLP_1.targets)\n",
    "print(\"Data: \\n\",MLP_1.data)\n",
    "MLP_1._gradient(np.array([0, 1, 2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Initial weights:  [[ 1.        ]\n",
      " [ 0.98576224]\n",
      " [ 0.9594031 ]\n",
      " [ 0.83024386]\n",
      " [ 0.37949296]\n",
      " [ 0.9569474 ]]\n",
      "Guess:  [[ 0.67279448]]  and target:  -1.0\n",
      "Grad:  [[ 0.22014207]] \n",
      " Error: [[-1.67279448]]\n",
      "Weight change:  [[-0.01841262]]\n",
      "Pre new weightz:  [[ 0.98158738]\n",
      " [ 0.96734962]\n",
      " [ 0.94099048]\n",
      " [ 0.81183124]\n",
      " [ 0.36108033]\n",
      " [ 0.93853478]]\n",
      "New weights:  [[ 0.19626355]\n",
      " [ 0.19341678]\n",
      " [ 0.1881464 ]\n",
      " [ 0.16232165]\n",
      " [ 0.07219623]\n",
      " [ 0.18765539]]\n",
      "Guess:  [[ 0.53859096]]  and target:  1.0\n",
      "Grad:  [[ 0.24851074]] \n",
      " Error: [[ 0.46140904]]\n",
      "Weight change:  [[ 0.00573326]]\n",
      "Pre new weightz:  [[ 0.2019968 ]\n",
      " [ 0.19915004]\n",
      " [ 0.19387965]\n",
      " [ 0.1680549 ]\n",
      " [ 0.07792948]\n",
      " [ 0.19338865]]\n",
      "New weights:  [[ 0.19527929]\n",
      " [ 0.19252719]\n",
      " [ 0.18743208]\n",
      " [ 0.16246614]\n",
      " [ 0.0753379 ]\n",
      " [ 0.1869574 ]]\n",
      "Guess:  [[ 0.55973372]]  and target:  -1.0\n",
      "Grad:  [[ 0.24643188]] \n",
      " Error: [[-1.55973372]]\n",
      "Weight change:  [[-0.01921841]]\n",
      "Pre new weightz:  [[ 0.17606088]\n",
      " [ 0.17330878]\n",
      " [ 0.16821367]\n",
      " [ 0.14324774]\n",
      " [ 0.05611949]\n",
      " [ 0.167739  ]]\n",
      "New weights:  [[ 0.19900866]\n",
      " [ 0.19589785]\n",
      " [ 0.19013864]\n",
      " [ 0.16191865]\n",
      " [ 0.0634341 ]\n",
      " [ 0.1896021 ]]\n",
      "Guess:  [[ 0.63397189]]  and target:  1.0\n",
      "Grad:  [[ 0.23205153]] \n",
      " Error: [[ 0.36602811]]\n",
      "Weight change:  [[ 0.00424687]]\n",
      "Pre new weightz:  [[ 0.20325553]\n",
      " [ 0.20014472]\n",
      " [ 0.19438551]\n",
      " [ 0.16616552]\n",
      " [ 0.06768097]\n",
      " [ 0.19384897]]\n",
      "New weights:  [[ 0.19820502]\n",
      " [ 0.19517151]\n",
      " [ 0.18955541]\n",
      " [ 0.16203663]\n",
      " [ 0.06599923]\n",
      " [ 0.1890322 ]]\n",
      "Guess:  [[ 0.56040966]]  and target:  1.0\n",
      "Grad:  [[ 0.24635067]] \n",
      " Error: [[ 0.43959034]]\n",
      "Weight change:  [[ 0.00541467]]\n",
      "Pre new weightz:  [[ 0.20361969]\n",
      " [ 0.20058618]\n",
      " [ 0.19497008]\n",
      " [ 0.1674513 ]\n",
      " [ 0.0714139 ]\n",
      " [ 0.19444687]]\n",
      "New weights:  [[ 0.19721264]\n",
      " [ 0.19427459]\n",
      " [ 0.1888352 ]\n",
      " [ 0.16218231]\n",
      " [ 0.06916681]\n",
      " [ 0.18832845]]\n",
      "Guess:  [[ 0.55818037]]  and target:  -1.0\n",
      "Grad:  [[ 0.24661504]] \n",
      " Error: [[-1.55818037]]\n",
      "Weight change:  [[-0.01921354]]\n",
      "Pre new weightz:  [[ 0.17799911]\n",
      " [ 0.17506105]\n",
      " [ 0.16962166]\n",
      " [ 0.14296878]\n",
      " [ 0.04995327]\n",
      " [ 0.16911491]]\n",
      "New weights:  [[ 0.20119287]\n",
      " [ 0.19787197]\n",
      " [ 0.19172382]\n",
      " [ 0.16159799]\n",
      " [ 0.05646232]\n",
      " [ 0.19115104]]\n",
      "Guess:  [[ 0.63734968]]  and target:  1.0\n",
      "Grad:  [[ 0.23113507]] \n",
      " Error: [[ 0.36265032]]\n",
      "Weight change:  [[ 0.00419106]]\n",
      "Pre new weightz:  [[ 0.20538393]\n",
      " [ 0.20206303]\n",
      " [ 0.19591488]\n",
      " [ 0.16578905]\n",
      " [ 0.06065338]\n",
      " [ 0.1953421 ]]\n",
      "New weights:  [[ 0.20034595]\n",
      " [ 0.19710652]\n",
      " [ 0.19110918]\n",
      " [ 0.16172232]\n",
      " [ 0.05916558]\n",
      " [ 0.19055045]]\n",
      "Guess:  [[ 0.55889551]]  and target:  1.0\n",
      "Grad:  [[ 0.24653132]] \n",
      " Error: [[ 0.44110449]]\n",
      "Weight change:  [[ 0.0054373]]\n",
      "Pre new weightz:  [[ 0.20578326]\n",
      " [ 0.20254382]\n",
      " [ 0.19654648]\n",
      " [ 0.16715963]\n",
      " [ 0.06460288]\n",
      " [ 0.19598775]]\n",
      "New weights:  [[ 0.19928192]\n",
      " [ 0.19614483]\n",
      " [ 0.19033696]\n",
      " [ 0.16187853]\n",
      " [ 0.06256188]\n",
      " [ 0.18979588]]\n",
      "Guess:  [[ 0.35401519]]  and target:  -1.0\n",
      "Grad:  [[ 0.22868844]] \n",
      " Error: [[-1.35401519]]\n",
      "Weight change:  [[-0.01548238]]\n",
      "Pre new weightz:  [[ 0.18379954]\n",
      " [ 0.18066245]\n",
      " [ 0.17485458]\n",
      " [ 0.14639615]\n",
      " [ 0.0470795 ]\n",
      " [ 0.1743135 ]]\n",
      "New weights:  [[ 0.20262196]\n",
      " [ 0.19916361]\n",
      " [ 0.19276097]\n",
      " [ 0.16138819]\n",
      " [ 0.05190078]\n",
      " [ 0.19216448]]\n",
      "Guess:  [[ 0.64896163]]  and target:  1.0\n",
      "Grad:  [[ 0.22781043]] \n",
      " Error: [[ 0.35103837]]\n",
      "Weight change:  [[ 0.00399851]]\n",
      "Pre new weightz:  [[ 0.20662047]\n",
      " [ 0.20316212]\n",
      " [ 0.19675948]\n",
      " [ 0.1653867 ]\n",
      " [ 0.05589929]\n",
      " [ 0.19616299]]\n",
      "New weights:  [[ 0.20177957]\n",
      " [ 0.19840224]\n",
      " [ 0.19214961]\n",
      " [ 0.16151186]\n",
      " [ 0.05458963]\n",
      " [ 0.1915671 ]]\n"
     ]
    }
   ],
   "source": [
    "#print(\"Weights: \\n\",MLP_1.weights)\n",
    "#print(MLP_1.data)\n",
    "#print(MLP_1.weights)\n",
    "#print(MLP_1.data)\n",
    "MLP_1._feed_forward()\n",
    "#print(MLP_1.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
